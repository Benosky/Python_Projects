# -*- coding: utf-8 -*-
"""
Created on Tue May 30 22:36:51 2017

@author: BENJAMIN
"""

# -*- coding: utf-8 -*-
"""
Created on Mon May 29 23:42:27 2017

@author: BENJAMIN
"""

my_data=[['slashdot','USA','yes',18,'None'],
['google','France','yes',23,'Premium'],
['digg','USA','yes',24,'Basic'],
['kiwitobes','France','yes',23,'Basic'],
['google','UK','no',21,'Premium'],
['(direct)','New Zealand','no',12,'None'],
['(direct)','UK','no',21,'Basic'],
['google','USA','no',24,'Premium'],
['slashdot','France','yes',19,'None'],
['digg','USA','no',18,'None'],
['google','UK','no',18,'None'],
['kiwitobes','UK','no',19,'None'],
['digg','New Zealand','yes',12,'Basic'],
['slashdot','UK','no',21,'None'],
['google','UK','yes',18,'Basic'],
['kiwitobes','France','yes',19,'Basic']]


class decisionnode:
    def __init__(self,col=-1,value=None,results=None,tb=None,fb=None):
        self.col=col
        self.value=value
        self.results=results
        self.tb=tb
        self.fb=fb



# Divides a set on a specific column. Can handle numeric
# or nominal values
def divideset(data,column,value):
    # Make a function that tells us if a row is in
    # the first group (true) or the second group (false)
    split_function=None
    if isinstance(value,str) or isinstance(value,str):
        split_function=lambda row:row[column]>=value
    else:
        split_function=lambda row:row[column]==value
# Divide the rows into two sets and return them
    set1=[row for row in data if split_function(row)]
    set2=[row for row in data if not split_function(row)]
    return (set1,set2)

#Uniquecounts presents the mixture of none who have signed up 
#and those who signed up for premium and basic
def uniquecounts(data):
    results={}
    for row in data:
        # The result is the last column
        r=row[len(row)-1]
        if r not in results: results[r]=0
        results[r]+=1
    return results

# Entropy is the sum of p(x)log(p(x)) across all
# the different possible results
def entropy(data):
    import math 
    results=uniquecounts(data)
    # Now calculate the entropy
    ent=0.0
    for r in results.keys():
        p=float(results[r])/len(data)
        ent=ent-p*math.log2(p)
    return ent

def gain(data, attr, target_attr):
    """
    Calculates the information gain (reduction in entropy) that would
    result by splitting the data on the chosen attribute (attr).
    """
    val_freq       = {}
    subset_entropy = 0.0

    # Calculate the frequency of each of the values in the target attribute
    uniquecounts(data)

    # Calculate the sum of the entropy for each subset of records weighted
    # by their probability of occuring in the training set.
    for val in uniquecounts(data).keys():
        val_prob        = uniquecounts(data)[val] / sum(val_freq.values())
        data_subset     = [record for record in data if record[attr] == val]
        subset_entropy += val_prob * entropy(data_subset)

    # Subtract the entropy of the chosen attribute from the entropy of the
    # whole data set with respect to the target attribute (and return it)
    return (entropy(data) - subset_entropy)



def buildtree(data, scorefun=entropy):
    if len(data) == 0: return decisionnode()
    current_score = scorefun(data)
    best_gain = 0.0
    best_criteria = None
    best_sets = None

    column_count = len(data[0]) - 1	# last column is result
    for col in range(0, column_count):
        # find different values in this column
        column_values = set([row[col] for row in data])

        # for each possible value, try to divide on that value
        for value in column_values:
            set1, set2 = divideset(data, col, value)

            # Information gain
            p = float(len(set1)) / len(data)
            gain = current_score - p*scorefun(set1) - (1-p)*scorefun(set2)
            if gain > best_gain and len(set1) > 0 and len(set2) > 0:
                best_gain = gain
                best_criteria = (col, value)
                best_sets = (set1, set2)

    if best_gain > 0:
        trueBranch = buildtree(best_sets[0])
        falseBranch = buildtree(best_sets[1])
        return decisionnode(col=best_criteria[0], value=best_criteria[1],
                tb=trueBranch, fb=falseBranch)
    else:
        return decisionnode(results=uniquecounts(data))
    

from PIL import Image,ImageDraw

def getwidth(tree):
  if tree.tb==None and tree.fb==None: return 1
  return getwidth(tree.tb)+getwidth(tree.fb)

def getdepth(tree):
  if tree.tb==None and tree.fb==None: return 0
  return max(getdepth(tree.tb),getdepth(tree.fb))+1

def drawnode(draw,tree,x,y):
    if tree.results==None:
        # Get the width of each branch
        w1=getwidth(tree.fb)*100
        w2=getwidth(tree.tb)*100
        # Determine the total space required by this node
        left=x-(w1+w2)/2
        right=x+(w1+w2)/2
        # Draw the condition string
        draw.text((x-20,y-10),str(tree.col)+':'+str(tree.value),(0,0,0))
        # Draw links to the branches
        draw.line((x,y,left+w1/2,y+100),fill=(255,0,0))
        draw.line((x,y,right-w2/2,y+100),fill=(255,0,0))
        # Draw the branch nodes
        drawnode(draw,tree.fb,left+w1/2,y+100)
        drawnode(draw,tree.tb,right-w2/2,y+100)
    else:
        txt='\n'.join(['%s:%d'%v for v in tree.results.items()])   
        draw.text((x-20,y),txt,(0,0,0))

def drawtree(tree,jpeg='tree.jpg'):
    w=getwidth(tree)*100
    h=getdepth(tree)*100+120
    img=Image.new('RGB',(w,h),(255,255,255))
    draw=ImageDraw.Draw(img)
    drawnode(draw,tree,w/2,20)
    img.save(jpeg,'JPEG')
    

        
drawtree(buildtree(my_data, scorefun=entropy),jpeg='tree.jpg')   

